{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c91c95d",
   "metadata": {},
   "source": [
    "# SLA1 Camera Characterization\n",
    "\n",
    "## PSF Candidates in 30s Darks\n",
    "\n",
    "On May 8, 2024 (UTC) we took various dark exposures with the [QHY42 Pro](https://www.qhyccd.com/qhy42pro/) camera.\n",
    "\n",
    "As they are read in, the darks are scaled to undo zero padding (divided by 16) and the effect of gain (multiplied by 1.39).\n",
    "\n",
    "They are then combined into a master dark. The master dark is subtracted from the individual darks.\n",
    "\n",
    "Then we find pixels that (a) exceed a threshold of 200 e- and (b) are\n",
    "brighter than their four nearest neighbors. These are the &ldquo;hot pixel leaders.&rdquo;\n",
    "\n",
    "Then we cull the hot pixel leaders whose neighbors fall off too sharply\n",
    "using the following quick criterion for non-PSF-shaped regions: any hot pixel leader that has a neighbor <20% of the peak is not a PSF candidate.\n",
    "\n",
    "Finally, the region around these candidates is displayed.\n",
    "\n",
    "### Notes\n",
    "\n",
    "The pixels are 1.5x1.5 arcsec. In seeing of FWHM=3 arcsec, the PSF will have a FWHM=2 pixels.\n",
    "\n",
    "A better criterion to consider implementing later:\n",
    "\n",
    "Compute the probability that the  5x5 pixels (with >200 e-) could have been drawn from the PSF shape plus Poisson noise. Essentially chi-squared. Normalize perhaps by the peak value set to 1.0, or normalized by total area.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d9d239c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: FITSFixedWarning: 'datfix' made the change 'Set MJD-OBS to -678575.000000 from DATE-OBS.\n",
      "Set MJD-END to 60438.151953 from DATE-END'. [astropy.wcs.wcs]\n",
      "WARNING:astropy:FITSFixedWarning: 'datfix' made the change 'Set MJD-OBS to -678575.000000 from DATE-OBS.\n",
      "Set MJD-END to 60438.151953 from DATE-END'.\n",
      "WARNING: FITSFixedWarning: 'datfix' made the change 'Set MJD-OBS to -678575.000000 from DATE-OBS.\n",
      "Set MJD-END to 60438.152301 from DATE-END'. [astropy.wcs.wcs]\n",
      "WARNING:astropy:FITSFixedWarning: 'datfix' made the change 'Set MJD-OBS to -678575.000000 from DATE-OBS.\n",
      "Set MJD-END to 60438.152301 from DATE-END'.\n",
      "WARNING: FITSFixedWarning: 'datfix' made the change 'Set MJD-OBS to -678575.000000 from DATE-OBS.\n",
      "Set MJD-END to 60438.152648 from DATE-END'. [astropy.wcs.wcs]\n",
      "WARNING:astropy:FITSFixedWarning: 'datfix' made the change 'Set MJD-OBS to -678575.000000 from DATE-OBS.\n",
      "Set MJD-END to 60438.152648 from DATE-END'.\n",
      "WARNING: FITSFixedWarning: 'datfix' made the change 'Set MJD-OBS to -678575.000000 from DATE-OBS.\n",
      "Set MJD-END to 60438.152995 from DATE-END'. [astropy.wcs.wcs]\n",
      "WARNING:astropy:FITSFixedWarning: 'datfix' made the change 'Set MJD-OBS to -678575.000000 from DATE-OBS.\n",
      "Set MJD-END to 60438.152995 from DATE-END'.\n",
      "WARNING: FITSFixedWarning: 'datfix' made the change 'Set MJD-OBS to -678575.000000 from DATE-OBS.\n",
      "Set MJD-END to 60438.153342 from DATE-END'. [astropy.wcs.wcs]\n",
      "WARNING:astropy:FITSFixedWarning: 'datfix' made the change 'Set MJD-OBS to -678575.000000 from DATE-OBS.\n",
      "Set MJD-END to 60438.153342 from DATE-END'.\n",
      "WARNING: FITSFixedWarning: 'datfix' made the change 'Set MJD-OBS to -678575.000000 from DATE-OBS.\n",
      "Set MJD-END to 60438.153689 from DATE-END'. [astropy.wcs.wcs]\n",
      "WARNING:astropy:FITSFixedWarning: 'datfix' made the change 'Set MJD-OBS to -678575.000000 from DATE-OBS.\n",
      "Set MJD-END to 60438.153689 from DATE-END'.\n",
      "WARNING: FITSFixedWarning: 'datfix' made the change 'Set MJD-OBS to -678575.000000 from DATE-OBS.\n",
      "Set MJD-END to 60438.154037 from DATE-END'. [astropy.wcs.wcs]\n",
      "WARNING:astropy:FITSFixedWarning: 'datfix' made the change 'Set MJD-OBS to -678575.000000 from DATE-OBS.\n",
      "Set MJD-END to 60438.154037 from DATE-END'.\n",
      "WARNING: FITSFixedWarning: 'datfix' made the change 'Set MJD-OBS to -678575.000000 from DATE-OBS.\n",
      "Set MJD-END to 60438.154384 from DATE-END'. [astropy.wcs.wcs]\n",
      "WARNING:astropy:FITSFixedWarning: 'datfix' made the change 'Set MJD-OBS to -678575.000000 from DATE-OBS.\n",
      "Set MJD-END to 60438.154384 from DATE-END'.\n",
      "WARNING: FITSFixedWarning: 'datfix' made the change 'Set MJD-OBS to -678575.000000 from DATE-OBS.\n",
      "Set MJD-END to 60438.154731 from DATE-END'. [astropy.wcs.wcs]\n",
      "WARNING:astropy:FITSFixedWarning: 'datfix' made the change 'Set MJD-OBS to -678575.000000 from DATE-OBS.\n",
      "Set MJD-END to 60438.154731 from DATE-END'.\n",
      "WARNING: FITSFixedWarning: 'datfix' made the change 'Set MJD-OBS to -678575.000000 from DATE-OBS.\n",
      "Set MJD-END to 60438.155078 from DATE-END'. [astropy.wcs.wcs]\n",
      "WARNING:astropy:FITSFixedWarning: 'datfix' made the change 'Set MJD-OBS to -678575.000000 from DATE-OBS.\n",
      "Set MJD-END to 60438.155078 from DATE-END'.\n"
     ]
    }
   ],
   "source": [
    "# THIS COMMENT IS THE LONGEST A LINE CAN BE AND STILL RENDER COMPLETELY WHEN PRINTING IN LANDSCAPE MODE.\n",
    "\n",
    "import os, sys\n",
    "import numpy as np\n",
    "from astropy import units as u\n",
    "from astropy.nddata import CCDData\n",
    "from astropy.io import fits\n",
    "from ccdproc import ImageFileCollection, combine, subtract_dark, flat_correct # Combiner\n",
    "import astroalign as aa\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from math import log10, floor\n",
    "\n",
    "home_directory = os.path.expanduser('~')\n",
    "\n",
    "# soft link to directory containing raw images\n",
    "sessions_directory = os.path.join(home_directory, '2024 SLA Sessions')\n",
    "\n",
    "uv_project_directory = os.path.join(home_directory, 'Projects', 'uv-transients')\n",
    "analysis_directory = os.path.join(uv_project_directory, 'analyses', '30s_darks')\n",
    "\n",
    "# The path to the first dark on SLA1 is D:/Raw/2024-05-08/03_38_48/Dark30s/00001.fits\n",
    "# The files to be processed need to be mirrored on the local machine\n",
    "# at ~/2024 SLA Sessions/ using the same subdirectory structure.\n",
    "capture_date = '2024-05-08'\n",
    "capture_time = '03_38_48'\n",
    "object_name = 'Dark30s'\n",
    "\n",
    "# Amount to scale the image data (typically to undo 0 padding of 12-bit to 16-bit values)\n",
    "\n",
    "scale_due_to_padding = 2**4  # This is division by 16\n",
    "\n",
    "scale_due_to_gain = 1.39  # from QHYCCD manual for gain of 5\n",
    "\n",
    "scale = scale_due_to_gain / scale_due_to_padding\n",
    "\n",
    "# threshold for flagging hot pixels\n",
    "\n",
    "threshold = 200\n",
    "\n",
    "# discontinuity limit\n",
    "\n",
    "ratio = 0.2\n",
    "\n",
    "# subdirectory for the 30-second darks (following SharpCap Pro capture directory conventions)\n",
    "dark_directory = os.path.join(\n",
    "    sessions_directory,\n",
    "    capture_date,\n",
    "    capture_time,\n",
    "    object_name\n",
    ")\n",
    "\n",
    "# exposure duration\n",
    "\n",
    "dark_exposure = 30.0\n",
    "dark_exposure_with_ccdproc_units = dark_exposure * u.second\n",
    "\n",
    "# FITS header confirmation\n",
    "\n",
    "def confirm_fits_header(image, dimensions, exposure_time, filter):\n",
    "    header = image.header\n",
    "    assert header['NAXIS1'] == dimensions[0]\n",
    "    assert header['NAXIS2'] == dimensions[1]\n",
    "    assert header['EXPTIME'] == exposure_time\n",
    "    if filter:\n",
    "        assert header['FILTER'].rstrip() == filter\n",
    "        \n",
    "# Reader with optional parameter to scale (divide) the ADU readings\n",
    "\n",
    "def scaled_image_reader(file, scale=1):\n",
    "    img = CCDData.read(file, unit=u.adu)\n",
    "    scaled_data = img.data * scale\n",
    "    img.data = scaled_data\n",
    "    return img\n",
    "\n",
    "# After all the preliminaries, we read in and combine the dark files\n",
    "\n",
    "dark_files = ImageFileCollection(dark_directory).files_filtered(include_path='True')\n",
    "\n",
    "darks = [scaled_image_reader(file, scale=scale) for file in dark_files]\n",
    "\n",
    "for dark in darks:\n",
    "    confirm_fits_header(dark, (2048, 2048), dark_exposure, None)\n",
    "\n",
    "combination_method = 'median'  # alternatively, the method can be 'average'\n",
    "\n",
    "master_dark = combine(darks, method=combination_method)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a85aaf4",
   "metadata": {},
   "source": [
    "## Subtract Master Dark from Darks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f285a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "subtracted_darks = [\n",
    "    subtract_dark(\n",
    "        dark,\n",
    "        master_dark,\n",
    "        data_exposure=dark_exposure_with_ccdproc_units,\n",
    "        dark_exposure=dark_exposure_with_ccdproc_units,\n",
    "        scale=False\n",
    "    )\n",
    "    for dark in darks\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f5020f",
   "metadata": {},
   "source": [
    "## Routines for Enumerating Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11f221bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "Pixel = namedtuple('Pixel', 'x y value')\n",
    "\n",
    "# Each of these routines may return fewer neighbors if the pixel is near the edge\n",
    "\n",
    "def __get_neighbors(pixel, offsets, data):\n",
    "    data_height, data_width = data.shape\n",
    "    neighbors = []\n",
    "    for offset_x, offset_y in offsets:\n",
    "        x = pixel.x + offset_x\n",
    "        y = pixel.y + offset_y\n",
    "        if x < 0 or y < 0 or x >= data_width or y >= data_height:\n",
    "            continue\n",
    "        neighbors.append(Pixel(x, y, data[y, x]))\n",
    "    return neighbors\n",
    "\n",
    "def get_four_neighbors(pixel, data):\n",
    "    offsets = [(-1, 0), (0, 1), (1, 0), (0, -1)]\n",
    "    return __get_neighbors(pixel, offsets, data)\n",
    "\n",
    "def get_eight_neighbors(pixel, data):\n",
    "    offsets = [(-1, 0), (-1, 1), (0, 1), (1, 1), (1, 0), (1, -1), (0, -1), (-1, -1)]\n",
    "    return __get_neighbors(pixel, offsets, data)\n",
    "\n",
    "def get_twelve_second_neighbors(pixel, data):\n",
    "    offsets = [(-2, 0), (-2, 1), (-1, 2), (0, 2), (1, 2), (2, 1),\n",
    "               (2, 0), (2, -1), (1, -2), (0, -2), (-1, -2), (-2, -1)]\n",
    "    return __get_neighbors(pixel, offsets, data)\n",
    "\n",
    "def get_sixteen_second_neighbors(pixel, data):\n",
    "    offsets = [(-2, 0), (-2, 1), (-2, 2), (-1, 2), (0, 2), (1, 2), (2, 2), (2, 1),\n",
    "               (2, 0), (2, -1), (2, -2), (1, -2), (0, -2), (-1, -2), (-2, -2), (-2, -1)]\n",
    "    return __get_neighbors(pixel, offsets, data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5483a24",
   "metadata": {},
   "source": [
    "## Routines for Finding Hot Pixel Leaders\n",
    "\n",
    "As a first cut, we will search for all pixels that exceed some threshold. These are the &ldquo;hot pixels.&rdquo;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73ff074e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_winner_or_tied(candidate_leader, neighbor):\n",
    "    return candidate_leader.value >= neighbor.value\n",
    "\n",
    "def is_leader(candidate_leader, data):\n",
    "    four_neighbors = get_four_neighbors(candidate_leader, data)\n",
    "    for neighbor in four_neighbors:\n",
    "        if not is_winner_or_tied(candidate_leader, neighbor):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def find_hot_pixel_leaders(data, threshold):\n",
    "    # first we simply find all the hot pixels\n",
    "    data_height, data_width = data.shape\n",
    "    exceedances = data > threshold  # an array of true-false values\n",
    "    values_of_exceedances = data[exceedances]\n",
    "    exceedance_indices = np.nonzero(exceedances)  # a crafty way of getting the indices of the exceedances\n",
    "    # all of the hot pixels are candidate leaders\n",
    "    candidate_leaders = np.transpose([exceedance_indices[1], exceedance_indices[0], values_of_exceedances])\n",
    "    leaders = []\n",
    "    for i in range(candidate_leaders.shape[0]):\n",
    "        row = candidate_leaders[i]\n",
    "        candidate_leader = Pixel(floor(row[0]), floor(row[1]), row[2])\n",
    "        if is_leader(candidate_leader, data):\n",
    "            leaders.append(candidate_leader)\n",
    "    return leaders\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60834df0",
   "metadata": {},
   "source": [
    "## Find the Hot Pixel Leaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4126788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there will be a list of leaders for each dark\n",
    "\n",
    "hot_pixel_leaders_for_darks = [\n",
    "    find_hot_pixel_leaders(subtracted_dark.data, threshold) for subtracted_dark in subtracted_darks\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5506f9bf",
   "metadata": {},
   "source": [
    "## Routines for Finding PSF Candidates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd8c7593",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_too_large(pixel, neighbor, ratio):\n",
    "    return ratio * pixel.value > neighbor.value\n",
    "\n",
    "def is_in_continuous_region(pixel, data, ratio, recurse=False):\n",
    "    four_neighbors = get_four_neighbors(pixel, data)\n",
    "    for neighbor in four_neighbors:\n",
    "        if is_too_large(pixel, neighbor, ratio):\n",
    "            return False\n",
    "    if recurse:\n",
    "        eight_neighbors = get_eight_neighbors(pixel, data)\n",
    "        twelve_second_neighbors = get_twelve_second_neighbors(pixel, data)\n",
    "        surrounding_region = eight_neighbors + twelve_second_neighbors\n",
    "        for neighbor in surrounding_region:\n",
    "            if not is_in_continuous_region(neighbor, data, ratio, recurse=False):\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "def find_psf_candidates(leaders, data, ratio):\n",
    "    candidates = [leader for leader in leaders if is_in_continuous_region(leader, data, ratio, recurse=True)]\n",
    "    return candidates\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779ec9aa",
   "metadata": {},
   "source": [
    "## Find the PSF Candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98c948c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates_for_darks = [\n",
    "    find_psf_candidates(hot_pixel_leaders, subtracted_darks[k].data, ratio)\n",
    "    for k, hot_pixel_leaders in enumerate(hot_pixel_leaders_for_darks)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580c2bd9",
   "metadata": {},
   "source": [
    "## Routine for Displaying PSF Candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "661e168f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DISPLAY_HALF_RANGE = 3\n",
    "DISPLAY_FULL_RANGE = 2 * DISPLAY_HALF_RANGE + 1\n",
    "\n",
    "def display_candidate(candidate, data):\n",
    "    \n",
    "    data_height, data_width = data.shape\n",
    "\n",
    "    lower_x = floor(candidate.x - DISPLAY_HALF_RANGE)\n",
    "    upper_x = floor(lower_x + DISPLAY_FULL_RANGE)\n",
    "    slice_x = slice(lower_x, upper_x)\n",
    "    lower_y = floor(candidate.y - DISPLAY_HALF_RANGE)\n",
    "    upper_y = floor(lower_y + DISPLAY_FULL_RANGE)\n",
    "    slice_y = slice(lower_y, upper_y)\n",
    "    \n",
    "    fig_size_x = 4\n",
    "    fig_size_y = 4\n",
    "    \n",
    "    # a bit of fussy code for dealing with display near the edges\n",
    "    # check x edges\n",
    "    if (lower_x < 0):\n",
    "        lower_x = 0\n",
    "        fig_size_x *= upper_x / DISPLAY_FULL_RANGE\n",
    "    elif (upper_x > data_width):\n",
    "        upper_x = data_width\n",
    "        fig_size_x *= (data_width - lower_x) / DISPLAY_FULL_RANGE\n",
    "    # check y edges\n",
    "    if (lower_y < 0):\n",
    "        lower_y = 0\n",
    "        fig_size_y *= upper_y / DISPLAY_FULL_RANGE\n",
    "    elif (upper_y > data_height):\n",
    "        upper_y = data_height\n",
    "        fig_size_y *= (data_height - lower_y) / DISPLAY_FULL_RANGE\n",
    "\n",
    "    fig, axes = plt.subplots(1, 1, figsize=(fig_size_x, fig_size_y))\n",
    "    \n",
    "    print(\"{} is a PSF candidate with neighbor values:\".format(candidate))\n",
    "    \n",
    "    for offset_y, offset_x in [(-1, 0), (0, 1), (1, 0), (0, -1)]:\n",
    "        j = floor(candidate.y + offset_y)\n",
    "        i = floor(candidate.x + offset_x)\n",
    "        if j < 0 or j >= data_height or i < 0 or i >= data_width:\n",
    "            continue\n",
    "        print(\"    x={}, y={}, value={}\".format(i, j, data[j][i]))\n",
    "    \n",
    "    title = \"PSF candidate at ({}, {})\".format(candidate.x, candidate.y)\n",
    "    \n",
    "    subframe = data[lower_y:upper_y, lower_x:upper_x]\n",
    "    \n",
    "    axes.imshow(subframe, cmap='gray')\n",
    "    axes.set_title(title, fontsize=12)\n",
    "    axes.set_xlabel('x')\n",
    "    axes.set_ylabel('y')\n",
    "    axes.invert_yaxis()\n",
    "    \n",
    "    xpositions = range(upper_x - lower_x)\n",
    "    xlabels = [str(x + lower_x) for x in xpositions]\n",
    "    ypositions = range(upper_y - lower_y)\n",
    "    ylabels = [str(y + lower_y) for y in ypositions]\n",
    "    \n",
    "    axes.set_xticks(xpositions, xlabels)\n",
    "    axes.set_yticks(ypositions, ylabels)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45d150a",
   "metadata": {},
   "source": [
    "## Display the PSF Candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46215c66",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No candidates for 00001.fits\n",
      "No candidates for 00002.fits\n",
      "No candidates for 00003.fits\n",
      "No candidates for 00004.fits\n",
      "No candidates for 00005.fits\n",
      "No candidates for 00006.fits\n",
      "No candidates for 00007.fits\n",
      "No candidates for 00008.fits\n",
      "No candidates for 00009.fits\n",
      "No candidates for 00010.fits\n"
     ]
    }
   ],
   "source": [
    "for k in range(len(candidates_for_darks)):\n",
    "    candidates = candidates_for_darks[k]\n",
    "    subtracted_dark_data = subtracted_darks[k].data\n",
    "    basename = os.path.basename(dark_files[k])\n",
    "    how_many = len(candidates)\n",
    "    if how_many > 0:\n",
    "        print('Displaying {} candidate(s) for {}'.format(how_many, basename))\n",
    "        for candidate in candidates:\n",
    "            display_candidate(candidate, subtracted_dark_data)\n",
    "    else:\n",
    "        print('No candidates for {}'.format(basename))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
