{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c91c95d",
   "metadata": {},
   "source": [
    "# SLA1 Camera Characterization\n",
    "\n",
    "## Calibration of 10s Darks\n",
    "\n",
    "On April 17, 2024 (UTC) we took various dark exposures with the [QHY42 Pro](https://www.qhyccd.com/qhy42pro/) camera.\n",
    "\n",
    "This notebook combines the darks into a master dark, and then subtracts them from each individual dark\n",
    "with the goal of characterizing hot pixels and dark current.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9d239c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS COMMENT IS THE LONGEST A LINE CAN BE AND STILL RENDER COMPLETELY WHEN PRINTING IN LANDSCAPE MODE.\n",
    "\n",
    "import os\n",
    "\n",
    "sessions_directory = os.path.join(os.path.expanduser('~'), '2024 SLA Sessions')  # a soft link\n",
    "analysis_directory = os.path.join(os.path.expanduser('~'), 'analyses-10s_darks')  # a soft link\n",
    "\n",
    "# The path to the first dark via the soft link is:\n",
    "# ~/2024 SLA Sessions/2024-04-17/04_04_18/10sGain7Offset64/00001.fits\n",
    "capture_date = '2024-04-17'\n",
    "capture_time = '04_04_18'\n",
    "object_name = '10sGain7Offset64'\n",
    "\n",
    "# subdirectory for the 10-second darks (these are SharpCap Pro capture directory conventions)\n",
    "dark_directory = os.path.join(\n",
    "    sessions_directory,\n",
    "    capture_date,\n",
    "    capture_time,\n",
    "    object_name\n",
    ")\n",
    "\n",
    "import numpy as np\n",
    "from astropy import units as u\n",
    "from astropy.nddata import CCDData\n",
    "from astropy.io import fits\n",
    "from ccdproc import ImageFileCollection, combine, subtract_dark, flat_correct # Combiner\n",
    "import astroalign as aa\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# exposure duration\n",
    "\n",
    "dark_exposure = 10 * u.second  # our method presumes this equality\n",
    "\n",
    "def confirm_fits_header(image, dimensions, exposure_time, binning, camera_set_temperature, filter):\n",
    "    header = image.header\n",
    "    assert header['NAXIS1'] == dimensions[0]\n",
    "    assert header['NAXIS2'] == dimensions[1]\n",
    "    assert header['EXPTIME'] == exposure_time\n",
    "    assert header['XBINNING'] == binning\n",
    "    assert header['SET-TEMP'] == camera_set_temperature\n",
    "    if filter:\n",
    "        assert header['FILTER'].rstrip() == filter\n",
    "\n",
    "# Trimmed image reader utility (because the 3x3 binned images have a final row of zeros)\n",
    "\n",
    "def delete_last_rows_and_columns(arr, rows_to_delete, columns_to_delete):\n",
    "    row_count = np.shape(arr)[0]\n",
    "    arr = np.delete(arr, slice(row_count - rows_to_delete, row_count), 0)\n",
    "    column_count = np.shape(arr)[1]\n",
    "    arr = np.delete(arr, slice(column_count - columns_to_delete, column_count), 1)\n",
    "    return arr\n",
    "\n",
    "def trimmed_image_reader(file):\n",
    "    img = CCDData.read(file, unit=u.adu)\n",
    "    data = img.data\n",
    "    trimmed_data = delete_last_rows_and_columns(data, 1, 0)\n",
    "    img.data = trimmed_data\n",
    "    return img\n",
    "\n",
    "def observation_directory_for_date(observation_date):\n",
    "    return os.path.join(os.path.expanduser('~'), '2024 Sessions', observation_date)\n",
    "\n",
    "def light_directory_for_filter(observation_date, filter):\n",
    "    observation_directory = observation_directory_for_date(observation_date)\n",
    "    return os.path.join(observation_directory, filter)\n",
    "\n",
    "def calibrated_directory_for_filter(observation_date, filter):\n",
    "    observation_directory = observation_directory_for_date(observation_date)\n",
    "    return os.path.join(observation_directory, filter, 'calibrated')\n",
    "\n",
    "def aligned_directory_for_filter(observation_date, filter):\n",
    "    observation_directory = observation_directory_for_date(observation_date)\n",
    "    return os.path.join(observation_directory, filter, 'aligned')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c0228c",
   "metadata": {},
   "source": [
    "## Combine the Calibration Images into Masters\n",
    "\n",
    "### Calibration Images\n",
    "\n",
    "The calibration images are in ~/2024 Sessions/2024-04-12/. In turn, ~/2024 Sessions is\n",
    "actually a soft link to /Volumes/Astronomy Data/2024 Sessions/2024 Sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe69b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the date on which the calibration images were taken\n",
    "\n",
    "calibration_date = '2024-04-12'\n",
    "\n",
    "# calibration directory\n",
    "\n",
    "calibration_directory = os.path.join(observations_directory, calibration_date)\n",
    "\n",
    "# subdirectory for the 30-second darks\n",
    "\n",
    "dark_directory = os.path.join(calibration_directory, 'dark')\n",
    "\n",
    "# subdirectories for the 0.1-second g and r flats\n",
    "\n",
    "flat_directories_by_filter = {filter:os.path.join(calibration_directory, 'flat', filter)\n",
    "                              for filter in filters}\n",
    "\n",
    "# subdirectory for the biases (TheSky Professional Edition may indicate that these are 0.1-second darks)\n",
    "\n",
    "bias_directory = os.path.join(calibration_directory, 'bias')\n",
    "\n",
    "# Trimmed image reader utility (because the 3x3 binned images have a final row of zeros)\n",
    "\n",
    "def delete_last_rows_and_columns(arr, rows_to_delete, columns_to_delete):\n",
    "    row_count = np.shape(arr)[0]\n",
    "    arr = np.delete(arr, slice(row_count - rows_to_delete, row_count), 0)\n",
    "    column_count = np.shape(arr)[1]\n",
    "    arr = np.delete(arr, slice(column_count - columns_to_delete, column_count), 1)\n",
    "    return arr\n",
    "\n",
    "def trimmed_image_reader(file):\n",
    "    img = CCDData.read(file, unit=u.adu)\n",
    "    data = img.data\n",
    "    trimmed_data = delete_last_rows_and_columns(data, 1, 0)\n",
    "    img.data = trimmed_data\n",
    "    return img\n",
    "\n",
    "# darks\n",
    "\n",
    "dark_files = ImageFileCollection(dark_directory).files_filtered(include_path='True')\n",
    "darks = [trimmed_image_reader(file) for file in dark_files]\n",
    "\n",
    "for dark in darks:\n",
    "    confirm_fits_header(dark, (1381, 940), 30.0, 3, 0.0, 'dark')\n",
    "\n",
    "# flats by filter\n",
    "\n",
    "flat_files_by_filter = {filter:ImageFileCollection(flat_directory).files_filtered(include_path='True')\n",
    "                        for filter, flat_directory in flat_directories_by_filter.items()}\n",
    "flats_by_filter = {filter:[trimmed_image_reader(file) for file in flat_files]\n",
    "                   for filter, flat_files in flat_files_by_filter.items()}\n",
    "\n",
    "for filter, flats in flats_by_filter.items():\n",
    "    for flat in flats:\n",
    "        confirm_fits_header(flat, (1381, 940), 0.1, 3, 0.0, filter)\n",
    "                   \n",
    "# biases\n",
    "\n",
    "bias_files = ImageFileCollection(bias_directory).files_filtered(include_path='True')\n",
    "biases = [trimmed_image_reader(file) for file in bias_files]\n",
    "\n",
    "for bias in biases:\n",
    "    confirm_fits_header(bias, (1381, 940), 0.1, 3, 0.0, 'dark')\n",
    "\n",
    "# Combine darks, flats, and biases\n",
    "\n",
    "calibration_combination_method = 'median'  # alternatively, the method can be 'average'\n",
    "\n",
    "master_dark = combine(darks, method=calibration_combination_method)\n",
    "master_flats_by_filter = {filter:combine(flats, method=calibration_combination_method)\n",
    "                         for filter, flats in flats_by_filter.items()}\n",
    "master_bias = combine(biases, method=calibration_combination_method)\n",
    "\n",
    "# Perform dark subtraction of the master flats\n",
    "\n",
    "master_flats_subtracted_by_filter = {filter:subtract_dark(master_flat,\n",
    "                                                          master_bias,\n",
    "                                                          data_exposure=flat_exposure,\n",
    "                                                          dark_exposure=bias_exposure,\n",
    "                                                          scale=False)\n",
    "                                     for filter, master_flat in master_flats_by_filter.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76465a34",
   "metadata": {},
   "source": [
    "## Load, Calibrate, Align, and Stack Lights\n",
    "\n",
    "What follows is a giant for loop, done once for each observation date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba069d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS COMMENT IS THE LONGEST A LINE CAN BE AND STILL RENDER COMPLETELY WHEN PRINTING IN LANDSCAPE MODE.\n",
    "\n",
    "aa.PIXEL_TOL = 3  # raised this from the default of 2 due to sometimes poor seeing or wind shake\n",
    "aa.MIN_MATCHES_FRACTION = 0.2  # lowered this from the default of 0.8\n",
    "aa.NUM_NEAREST_NEIGHBORS = 7  # raised this from the default of 5\n",
    "detection_sigma = 1.4 # lowered this from the default of 3.0 to align soft images, especially 2024-03-23\n",
    "\n",
    "alignment_reference_date = '2024-04-04'\n",
    "alignment_reference_filter = 'r'\n",
    "alignment_reference_filename = '00006442.NGC 3443.fit'\n",
    "alignment_reference_filepath = os.path.join(\n",
    "    light_directory_for_filter(alignment_reference_date, alignment_reference_filter),\n",
    "    alignment_reference_filename\n",
    ")\n",
    "alignment_reference_image = trimmed_image_reader(alignment_reference_filepath)\n",
    "\n",
    "# The following detection_sigmas worked -- when aligning a single night/filter data with itself.\n",
    "# The defaults had to be further adjusted to align all sessions/filters to one reference session/filter.\n",
    "\n",
    "# observation_dates = [\n",
    "#     SUCCESS W/ 2.5 '2024-03-20',\n",
    "#     SUCCESS W/ 2.0 '2024-03-21',\n",
    "#     SUCCESS W/ 2.0 '2024-03-23',\n",
    "#     SUCCESS W/ 3.0 '2024-03-27',\n",
    "#     SUCCESS W/ 3.0 '2024-04-02',\n",
    "#     SUCCESS W/ 3.0 '2024-04-03',\n",
    "#     SUCCESS W/ 3.0 '2024-04-04',\n",
    "#     SUCCESS W/ 3.0 '2024-04-06',\n",
    "#     SUCCESS W/ 3.0 '2024-04-10',\n",
    "#     SUCCESS W/ 3.0 '2024-04-11',\n",
    "#     SUCCESS W/ 2.0 '2024-04-13',\n",
    "#     SUCCESS W/ 3.0 '2024-04-17',\n",
    "#     SUCCESS W/ 2.0 '2024-04-21',\n",
    "#     SUCCESS W/ 2.0 '2024-04-22',\n",
    "#     SUCCESS W/ 2.0 '2024-04-23',\n",
    "#     SUCCESS W/ 3.0 '2024-04-29',\n",
    "#     SUCCESS W/ 3.0 '2024-04-30',\n",
    "#     SUCCESS W/ 3.0 '2024-05-02'\n",
    "# ]\n",
    "\n",
    "# NOW THE REAL CHALLENGE -- GETTING THEM ALL TO ALIGN WITH A SINGLE REFERENCE IMAGE\n",
    "\n",
    "alignment_reference_date = '2024-04-04'\n",
    "alignment_reference_filter = 'r'\n",
    "alignment_reference_filename = '00006442.NGC 3443.fit'\n",
    "alignment_reference_filepath = os.path.join(\n",
    "    light_directory_for_filter(alignment_reference_date, alignment_reference_filter),\n",
    "    alignment_reference_filename\n",
    ")\n",
    "alignment_reference_image = trimmed_image_reader(alignment_reference_filepath)\n",
    "\n",
    "\n",
    "observation_dates = [\n",
    "    '2024-03-20',\n",
    "    '2024-03-21',\n",
    "    '2024-03-23',  # 2024-03-23 was hardest to align -- it forced the most change in astroalign defaults\n",
    "    '2024-03-27',\n",
    "    '2024-04-02',\n",
    "    '2024-04-03',\n",
    "    '2024-04-04',\n",
    "    '2024-04-06',\n",
    "    '2024-04-10',\n",
    "    '2024-04-11',\n",
    "    '2024-04-13',\n",
    "    '2024-04-17',\n",
    "    '2024-04-21',\n",
    "    '2024-04-22',\n",
    "    '2024-04-23',\n",
    "    '2024-04-29',\n",
    "    '2024-04-30',\n",
    "    '2024-05-02'\n",
    "]\n",
    "\n",
    "\n",
    "for observation_date in observation_dates:\n",
    "    observation_directory = os.path.join(os.path.expanduser('~'), '2024 Sessions', observation_date)\n",
    "    \n",
    "    # subdirectories for the 30-second g and r lights\n",
    "    \n",
    "    light_directories_by_filter = {\n",
    "        filter:os.path.join(observation_directory, filter)\n",
    "        for filter in filters\n",
    "    }\n",
    "    \n",
    "    # lights by filter\n",
    "    \n",
    "    light_files_by_filter = {\n",
    "        filter:ImageFileCollection(light_directory).files_filtered(include_path='True')\n",
    "        for filter, light_directory in light_directories_by_filter.items()\n",
    "    }\n",
    "    \n",
    "    lights_by_filter = {\n",
    "        filter:[trimmed_image_reader(file) for file in light_files]\n",
    "        for filter, light_files in light_files_by_filter.items()\n",
    "    }\n",
    "    \n",
    "    for filter, lights in lights_by_filter.items():\n",
    "        for light in lights:\n",
    "            confirm_fits_header(light, (1381, 940), 30.0, 3, 0.0, filter)\n",
    "    \n",
    "    subtracted_lights_by_filter = {\n",
    "        filter:[subtract_dark(light,\n",
    "                              master_dark,\n",
    "                              data_exposure=light_exposure,\n",
    "                              dark_exposure=dark_exposure,\n",
    "                              scale=False) for light in lights]\n",
    "        for filter, lights in lights_by_filter.items()\n",
    "    }\n",
    "    \n",
    "    # Perform flat division\n",
    "    \n",
    "    calibrated_lights_by_filter = {\n",
    "        filter:[\n",
    "            flat_correct(light, master_flats_subtracted_by_filter[filter])\n",
    "            for light in lights\n",
    "        ]\n",
    "        for filter, lights in subtracted_lights_by_filter.items()\n",
    "    }\n",
    "    \n",
    "    # In this phase of the analysis, the aligned directories are written to not read from.\n",
    "\n",
    "    # create the aligned directories\n",
    "\n",
    "    aligned_directories_by_filter = {\n",
    "        filter:os.path.join(light_directory, 'aligned')\n",
    "        for filter, light_directory in light_directories_by_filter.items()\n",
    "    }\n",
    "\n",
    "    for aligned_directory in aligned_directories_by_filter.values():\n",
    "        if not os.path.exists(aligned_directory):\n",
    "            os.makedirs(aligned_directory)\n",
    "            \n",
    "            \n",
    "    lights_aligned_with_footprints_by_filter = { 'r': [], 'g': [] }\n",
    "\n",
    "    # Not using a list comprehension because it is easier with explicit loops to locate registration failures\n",
    "    for filter in filters:\n",
    "        print(filter)\n",
    "        for i in range(len(calibrated_lights_by_filter[filter])):\n",
    "            print(observation_date, filter, i, light_files_by_filter[filter][i])\n",
    "            ##############################################################\n",
    "            # THE FOLLOWING CALL IS FUSSY AND OFTEN FAILS ON POOR IMAGES #\n",
    "            ##############################################################\n",
    "            lights_aligned_with_footprints_by_filter[filter].append(\n",
    "                aa.register(calibrated_lights_by_filter[filter][i],\n",
    "                            alignment_reference_image,\n",
    "                            detection_sigma=detection_sigma)\n",
    "            )\n",
    "    \n",
    "    # write the aligned lights\n",
    "\n",
    "    for filter in filters:\n",
    "        lights = lights_by_filter[filter]\n",
    "        light_files = light_files_by_filter[filter]\n",
    "        lights_aligned_with_footprints = lights_aligned_with_footprints_by_filter[filter]\n",
    "        aligned_directory = aligned_directories_by_filter[filter]\n",
    "        for j in range(len(lights_aligned_with_footprints)):\n",
    "            # Then we write all the files for that filter\n",
    "            light_header = lights[j][0].header\n",
    "            light_aligned_data = lights_aligned_with_footprints[j][0]\n",
    "            aligned_file = os.path.join(aligned_directory, os.path.basename(light_files[j]))\n",
    "            aligned_file2 = os.path.splitext(aligned_file)[0] + '_aligned.fit'\n",
    "            fits.writeto(aligned_file2, light_aligned_data, light_header, overwrite=True)\n",
    "\n",
    "    # read back in and stack the lights\n",
    "\n",
    "    aligned_lights_by_filter = {\n",
    "        filter:[CCDData.read(file, unit=u.adu)\n",
    "                for file in ImageFileCollection(aligned_directory).files_filtered(include_path='True')]\n",
    "        for filter, aligned_directory in aligned_directories_by_filter.items()\n",
    "    }\n",
    "\n",
    "    stacking_combination_method = 'median'  # alternatively, the method can be 'average'\n",
    "\n",
    "    combined_lights_by_filter = {\n",
    "        filter:combine(lights, method=stacking_combination_method)\n",
    "        for filter, lights in aligned_lights_by_filter.items()\n",
    "    }\n",
    "    \n",
    "    # create the directories where the stacked lights will be written\n",
    "\n",
    "    stacked_directory = os.path.join(analysis_directory, 'stacked')\n",
    "\n",
    "    if not os.path.exists(stacked_directory):\n",
    "        os.makedirs(stacked_directory)\n",
    "\n",
    "    # write the aligned lights\n",
    "\n",
    "    for filter in filters:\n",
    "        stacked_header = aligned_lights_by_filter[filter][0].header\n",
    "        stacked_data = combined_lights_by_filter[filter]\n",
    "        stacked_file = os.path.join(stacked_directory, observation_date + '-' + filter + '_stacked.fit')\n",
    "        fits.writeto(stacked_file, stacked_data, stacked_header, overwrite=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
